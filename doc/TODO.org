* DONE learn neural supersampling for real-time rendering

* DONE learn High-Quality Supersampling via Mask-reinforced Deep Learning for Real-time Rendering


* DONE study neural supersampling for real-time rendering 


* DONE learn code


* DONE run code

** DONE run train 1 epoch, small samples

problem:
- loss error

1.set preTrained=false
2.download vgg16
3.load model


- output is empty
value is target * 1/10

should print in 1,2 epoch and compare the whether output value increase!?


** DONE run test



* DONE learn detail

why need frames?
ans: for temporal stable 


# can need previous frames?


how can wspn do frame accu?reprojection?
yes



# * TODO implement type

TODO define MLGraphBuilder
use dependent type!


* DONE implement inference by webnn

# bdd test

run test
    # get weight, bias .npy

# fix: feature extract get 6 weight, bias

# feat: add bias for conv2d
    # pass bdd test

    pass run test

    # run test, see output!

    # weight,bias?
    # resize input?
    # model?
    upsample?
        use ``'linear'``
        align_corners=False ?


    # model use zero upsample?

    input_current_frame_upsampled error?

    test one by one module

    change:
        height, width to 2, 1
        fake image data


# * TODO optimize


# * TODO video

* DONE write article

